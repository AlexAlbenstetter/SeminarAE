{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "from river import compose, metrics, preprocessing, stream, anomaly, linear_model, datasets, compose\n",
    "from river import feature_extraction as fx\n",
    "from IncrementalTorch.anomaly.anomaly import TorchAE, SklearnAnomalyDetector\n",
    "from tqdm import tqdm\n",
    "import river  \n",
    "import torchvision\n",
    "from pprint import pprint\n",
    "\n",
    "from OnlineTorch.classifier import PyTorch2RiverClassifier\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "\n",
    "N_SAMPLES = 1_000\n",
    "SEED = 42\n",
    "track_name = \"RBF\"\n",
    "#LOSS = nn.BCELoss\n",
    "LOSS = nn.L1Loss\n",
    "OPTIMIZER = optim.AdamW\n",
    "BATCH_SIZE=1\n",
    "LEARNING_RATE=1e-3\n",
    "METRIC = river.metrics.ROCAUC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stream = stream.shuffle(river.datasets.CreditCard().take(8000), 1000, seed=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "## Undercomplete Autoencoder\n",
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undercomplete_ae_sm(n_features, latent_dim=1):\n",
    "    net = nn.Sequential(\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(n_features, 20), \n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(20, latent_dim),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(latent_dim, 20),\n",
    "        nn.LeakyReLU(), \n",
    "        nn.Linear(20, n_features),\n",
    "        nn.Linear(n_features,1),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undercomplete Autoencoder standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undercomplete_ae(n_features, latent_dim=1):\n",
    "    net = nn.Sequential(\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(n_features, 20), \n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(20, latent_dim),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(latent_dim, 20),\n",
    "        nn.LeakyReLU(), \n",
    "        nn.Linear(20, n_features),\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    PyTorch2RiverClassifier(\n",
    "                build_fn = undercomplete_ae_sm,\n",
    "                loss_fn = LOSS,\n",
    "                optimizer_fn = OPTIMIZER,\n",
    "                #batch_size=BATCH_SIZE,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                seed=SEED\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = compose.Pipeline(\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    TorchAE(\n",
    "                build_fn = undercomplete_ae,\n",
    "                loss_fn = LOSS,\n",
    "                optimizer_fn = OPTIMIZER,\n",
    "                #batch_size=BATCH_SIZE,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                seed=SEED\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manuel\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 0.496552"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#supervised learning approach with Softmax function --> Proba gets predicted, ROC way worse\n",
    "metric = river.metrics.ROCAUC()\n",
    "data_stream = stream.shuffle(river.datasets.CreditCard().take(8000), N_SAMPLES, seed=42)\n",
    "for x, y in data_stream:\n",
    "    y_pred = model1.predict_proba_one(x) #ruft learn_unsupervised auf, m端ssen wir learn_one dann 端berhaupt auch aufrufen?\n",
    "    model1.learn_one(x, y) #model1.learn_one ist supervised Ansatz, wir wollen Unsupervised\n",
    "    metric.update(y, y_pred)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1+cpu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROCAUC: -0."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric= river.metrics.ROCAUC()\n",
    "data_stream = stream.shuffle(river.datasets.CreditCard().take(8000), N_SAMPLES, seed=42)\n",
    "for x, y in data_stream:\n",
    "    model2.learn_one(x)\n",
    "    y_pred= model2.score_one(x)\n",
    "    metric.update(y,y_pred)\n",
    "    #model2.learn_one(x,y_pred)\n",
    "    #model2.learn_one(x,learn_unsupervised=True)\n",
    "    #y_pred = model1.predict_proba_one(x) #ruft learn_unsupervised auf, m端ssen wir learn_one dann 端berhaupt auch aufrufen?\n",
    "    #model2.learn_one(x, y)\n",
    "    #METRIC.update(y, y_pred)\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "river.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "## OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    #fx.RBFSampler(),    \n",
    "    anomaly.QuantileThresholder(\n",
    "        anomaly.OneClassSVM(),\n",
    "        q=0.97 #q Anpassung viele Auswirkungen\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROCAUC: 0.803009"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric= river.metrics.ROCAUC()\n",
    "data_stream = stream.shuffle(river.datasets.CreditCard().take(8000), N_SAMPLES, seed=42)\n",
    "for x, y in data_stream:\n",
    "    model4.learn_one(x)\n",
    "    y_pred= model4.score_one(x)\n",
    "    metric.update(y,y_pred)\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalfSpaceTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = compose.Pipeline(\n",
    "    preprocessing.Sta(),\n",
    "    anomaly.HalfSpaceTrees(seed=SEED)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROCAUC: 0.851694"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric= river.metrics.ROCAUC()\n",
    "data_stream = stream.shuffle(river.datasets.CreditCard().take(8000), N_SAMPLES, seed=42)\n",
    "for x, y in data_stream:\n",
    "    model3.learn_one(x)\n",
    "    y_pred= model3.score_one(x)\n",
    "    metric.update(y,y_pred)\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15576/4285092562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomRBF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     net = nn.Sequential(\n\u001b[0;32m      5\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = datasets.synth.RandomRBF(seed_model=7, seed_sample=seed,n_classes=10,n_features=200).take(n_samples)\n",
    "\n",
    "def build_fn(n_features):\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(n_features, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(5, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(5, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(5, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(5, 1),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "    return net\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    PyTorch2RiverClassifier(\n",
    "                build_fn=build_fn,\n",
    "                loss_fn=nn.BCELoss,\n",
    "                optimizer_fn=optim.Adam,\n",
    "                batch_size=1,\n",
    "                learning_rate=1e-3,\n",
    "    )\n",
    ")\n",
    "\n",
    "for x, y in data_stream:\n",
    "    y_pred = model.predict_proba_one(x)\n",
    "    model.learn_one(x, y)\n",
    "    METRIC.update(y, y_pred)\n",
    "METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43d093f43044a3a65e6980dc28089ab95a7d3d66b3284b0379db52f7d7b16821"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('rwch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
