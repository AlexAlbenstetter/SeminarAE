{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "from river import compose, metrics, preprocessing, stream, anomaly\n",
    "from OnlineTorch.anomaly import TorchAE, SklearnAnomalyDetector\n",
    "from tqdm import tqdm\n",
    "import river  \n",
    "import torchvision\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from util import build_anomaly_dataset, Tensor2Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_incremental(model, data, update_interv=100):\n",
    "    scores = []\n",
    "    truths = []\n",
    "    iterator = tqdm(data, unit='samples')\n",
    "    iterator.set_description('Learning from stream')\n",
    "    loss_sum = 0\n",
    "    idx = 0\n",
    "    for x, y in iterator:\n",
    "        model = model.learn_one(x)\n",
    "        score = model.score_one(x)\n",
    "        scores.append(score)\n",
    "        if isinstance(y, torch.Tensor):\n",
    "            y = y.item()\n",
    "        truths.append(y)\n",
    "        loss_sum += score\n",
    "        idx += 1\n",
    "        if idx == update_interv:\n",
    "            iterator.set_postfix({f'loss_{update_interv}': loss_sum/update_interv})\n",
    "            loss_sum = 0\n",
    "            idx = 0\n",
    "    return roc_auc_score(truths, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cae(n_features=1):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=n_features, out_channels=32,\n",
    "                  kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=3),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=8, out_channels=16,\n",
    "                           kernel_size=3, stride=3),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=16, out_channels=32,\n",
    "                           kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=32, out_channels=n_features,\n",
    "                           kernel_size=4, stride=2),\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "loss = nn.L1Loss\n",
    "optimizer = optim.AdamW\n",
    "model = TorchAE(build_fn=build_cae, loss_fn=loss, device=device,\n",
    "                optimizer_fn=optimizer, learning_rate=0.01, seed=42)\n",
    "\n",
    "model2 = Tensor2Dict() | anomaly.HalfSpaceTrees(seed=20)\n",
    "model3 = SklearnAnomalyDetector(SGDOneClassSVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucascazzonelli/Documents/incrementalae/.venv/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/home/lucascazzonelli/Documents/incrementalae/.venv/lib/python3.9/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "mnist = torchvision.datasets.MNIST('./data/', download=True)\n",
    "mnist_x, mnist_y = mnist.train_data.unsqueeze(1) / 255., mnist.targets\n",
    "mnist = build_anomaly_dataset(mnist_x, mnist_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning from stream: 100%|██████████| 9631/9631 [00:30<00:00, 313.77samples/s, loss_100=0.557]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8960713049498096"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_incremental(model=model2, data=mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cae_cifar(n_features=3):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=n_features, out_channels=64,\n",
    "                  kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=256, out_channels=128,\n",
    "                           kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                           kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=128, out_channels=64,\n",
    "                           kernel_size=3, stride=2),\n",
    "        nn.SELU(),\n",
    "        nn.ConvTranspose2d(in_channels=64, out_channels=n_features,\n",
    "                           kernel_size=3, stride=2),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning from stream: : 8000samples [00:07, 1000.88samples/s, loss_100=0.048]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9816225705329154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_ae(n_features, latent_dim=1):\n",
    "    model = nn.Sequential(\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(n_features, 20), \n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(20, latent_dim),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(latent_dim, 20),\n",
    "        nn.LeakyReLU(), \n",
    "        nn.Linear(20, n_features)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "loss =  nn.L1Loss\n",
    "optimizer = optim.AdamW\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    TorchAE(build_fn=build_ae, loss_fn=loss, optimizer_fn=optimizer, learning_rate=0.01, seed=42)\n",
    ")\n",
    "\n",
    "model2 = compose.Pipeline(\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    anomaly.HalfSpaceTrees(seed=20)\n",
    ")\n",
    "\n",
    "phishing = stream.shuffle(river.datasets.CreditCard().take(8000), 1000, seed=20)\n",
    "train_test_incremental(model, phishing)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e8b387b273876d5d45e7a8b26f076fc7482097c291cde7573e42877192c4357"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
